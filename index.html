<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Does it contain steg?</title>
</head>
<body>
    <h2>Does it contain steg?</h2>
    <h2>Leif, Jack, Griffin</h2>
    <input type="file" name="Image" onchange="inputChanged(event)" autocomplete="off">
    <p>
        Current status: <span id="status-output">Waiting for file</span>
    </p>
    <p>
        Model output: <span id="model-output"></span>
    </p>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        const statusDict = ["Waiting for file", "Loading file", "Performing inference", "Inference complete"];

        async function inference(path) {
            try {
                const session = await ort.InferenceSession.create('./finalProject_model.onnx');
                const imageTensor = await getImageTensorFromPath(path);
                const feeds = { input: imageTensor };
                const results = await session.run(feeds);
                return results.output.data;
            } catch (e) {
                return e;
            }
        }

        async function inputChanged(event) {
            const statusOutput = document.getElementById("status-output");
            const modelOutput = document.getElementById("model-output");

            statusOutput.textContent = statusDict[1];
            const inferenceResult = await inference(URL.createObjectURL(event.target.files[0]));

            // Update the model output here if needed
            modelOutput.textContent = "Performing inference...";

            // Assuming inferenceResult is a tensor
            displayPredictionResult(inferenceResult);

            statusOutput.textContent = statusDict[3];
        }

        function displayPredictionResult(inferenceResult) {
            // Example: Convert the tensor to an image and display it
            const [batchSize, numChannels, height, width] = inferenceResult.dims;

            const canvas = document.createElement('canvas');
            canvas.width = width;
            canvas.height = height;
            const ctx = canvas.getContext('2d');

            const imageData = inferenceResult.data;

            const imageDataObject = ctx.createImageData(width, height);

            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const offset = (y * width + x) * numChannels;
                    const r = Math.round(imageData[offset] * 255);
                    const g = Math.round(imageData[offset + 1] * 255);
                    const b = Math.round(imageData[offset + 2] * 255);
                    const a = 255;
                    const pixelOffset = (y * width + x) * 4;
                    imageDataObject.data[pixelOffset] = r;
                    imageDataObject.data[pixelOffset + 1] = g;
                    imageDataObject.data[pixelOffset + 2] = b;
                    imageDataObject.data[pixelOffset + 3] = a;
                }
            }

            ctx.putImageData(imageDataObject, 0, 0);

            const image = new Image();
            image.src = canvas.toDataURL();

            // Append the image to the result container
            const resultContainer = document.getElementById("model-output");
            resultContainer.innerHTML = ""; // Clear previous result
            resultContainer.appendChild(image);
        }
    </script>
</body>
</html>

